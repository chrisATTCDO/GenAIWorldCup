{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain_community pymupdf openai databricks-vectorsearch jq unstructured\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import logging as logger\n",
    "import io\n",
    "import base64\n",
    "import urllib.parse\n",
    "import platform\n",
    "import unicodedata\n",
    "import re\n",
    "from io import BytesIO\n",
    "from typing import List, Any, Optional\n",
    "\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "import openai\n",
    "import mlflow\n",
    "import mlflow.deployments\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from langchain_community.document_loaders import (\n",
    "    PyMuPDFLoader,\n",
    "    CSVLoader,\n",
    "    PyPDFLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    TextLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtensionLoader:\n",
    "    \"\"\"\n",
    "    A class to load extension configurations.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    loader_class : str\n",
    "        The class name of the file loader.\n",
    "    loader_kwargs : dict\n",
    "        The keyword arguments for the loader.\n",
    "    splitter_class : str\n",
    "        The class name of the splitter.\n",
    "    splitter_kwargs : dict\n",
    "        The keyword arguments for the splitter.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    __init__(ingestion_data: dict):\n",
    "        Initializes the ExtensionLoader with ingestion data.\n",
    "    \"\"\"\n",
    "    def __init__(self, ingestion_data: dict):\n",
    "        \"\"\"\n",
    "        Initialize the ExtensionLoader with ingestion data.\n",
    "\n",
    "        :param ingestion_data: Dictionary containing ingestion configuration.\n",
    "        \"\"\"\n",
    "        self.loader_class = ingestion_data.get(\"file_loader_class_name\")\n",
    "        self.loader_kwargs = ingestion_data.get(\"loader_kwargs\")\n",
    "        self.splitter_class = ingestion_data.get(\"splitter_class_name\")\n",
    "        self.splitter_kwargs = ingestion_data.get(\"splitter_kwargs\")\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    A class to handle configuration settings.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    __domain_data : dict\n",
    "        The domain data loaded from the configuration file.\n",
    "    __vector_store : dict\n",
    "        The vector store configuration.\n",
    "    __generator : dict\n",
    "        The generator configuration.\n",
    "    __vision : dict\n",
    "        The vision configuration.\n",
    "    __prompt : dict\n",
    "        The prompt configuration.\n",
    "    __ingestion_configuration : dict\n",
    "        The ingestion configuration.\n",
    "    __extension_configs : dict\n",
    "        The extension configurations.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    __init__(file_path: str):\n",
    "        Initializes the Config with a file path.\n",
    "    __load_extension_list() -> dict:\n",
    "        Loads the extension list from the ingestion configuration.\n",
    "    get_loader_for_extension(extension: str) -> Optional[ExtensionLoader]:\n",
    "        Gets the loader for a specific extension.\n",
    "    get_embedding_model() -> str:\n",
    "        Gets the embedding model name.\n",
    "    get_embedding_model_dimension() -> int:\n",
    "        Gets the embedding model dimension.\n",
    "    get_vector_index_schema() -> dict:\n",
    "        Gets the vector index schema.\n",
    "    get_vector_index_primary_key() -> str:\n",
    "        Gets the vector index primary key.\n",
    "    get_vector_index_vector_column() -> str:\n",
    "        Gets the vector index embedding vector column.\n",
    "    get_vector_endpoint() -> str:\n",
    "        Gets the vector endpoint name.\n",
    "    get_vector_index() -> str:\n",
    "        Gets the vector index name.\n",
    "    get_generator_endpoint() -> str:\n",
    "        Gets the generator endpoint name.\n",
    "    get_vision_endpoint() -> str:\n",
    "        Gets the vision endpoint name.\n",
    "    get_generator_model() -> str:\n",
    "        Gets the generator model name.\n",
    "    get_vector_query_type() -> str:\n",
    "        Gets the vector query type.\n",
    "    get_generator_prompt() -> str:\n",
    "        Gets the generator prompt.\n",
    "    get_symbol_identifier_prompt() -> str:\n",
    "        Gets the symbol identifier prompt.\n",
    "    get_symbol_conversation_prompt() -> str:\n",
    "        Gets the symbol conversation prompt.\n",
    "    get_multiturn_prompt() -> str:\n",
    "        Gets the multi-turn prompt.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the Config with a file path.\n",
    "\n",
    "        :param file_path: Path to the configuration file.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise Exception(\"Config File Path Not present\")\n",
    "        self.__domain_data = json.load(open(file_path, \"r\"))\n",
    "        self.__vector_store = self.__domain_data.get(\"vector_store\", None)\n",
    "        self.__generator = self.__domain_data.get(\"generator\", None)\n",
    "        self.__vision = self.__domain_data.get(\"vision\", None)\n",
    "        self.__prompt = self.__domain_data.get(\"prompts\", None)\n",
    "        self.__ingestion_configuration = self.__domain_data.get(\"ingestion\", None)\n",
    "        self.__extension_configs = self.__load_extension_list()\n",
    "\n",
    "    def __load_extension_list(self) -> dict:\n",
    "        \"\"\"\n",
    "        Load the extension list from the ingestion configuration.\n",
    "\n",
    "        :return: Dictionary of extension configurations.\n",
    "        \"\"\"\n",
    "        extension_configs = {}\n",
    "        if self.__ingestion_configuration:\n",
    "            for ingestion_data in self.__ingestion_configuration:\n",
    "                for extension in ingestion_data[\"extension\"]:\n",
    "                    extension_configs[extension] = ExtensionLoader(ingestion_data=ingestion_data)\n",
    "        return extension_configs\n",
    "\n",
    "    def get_loader_for_extension(self, extension: str) -> Optional[ExtensionLoader]:\n",
    "        \"\"\"\n",
    "        Get the loader for a specific extension.\n",
    "\n",
    "        :param extension: Extension name.\n",
    "        :return: ExtensionLoader object or None.\n",
    "        \"\"\"\n",
    "        return self.__extension_configs.get(extension, None)\n",
    "\n",
    "    def get_embedding_model(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the embedding model name.\n",
    "\n",
    "        :return: Embedding model name.\n",
    "        :raises Exception: If model details are not present.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            embedding = self.__vector_store.get(\"embedding\", None)\n",
    "            if embedding:\n",
    "                model = embedding.get(\"model\", None)\n",
    "                if model:\n",
    "                    return model\n",
    "        raise Exception(\"Model details Not Present\")\n",
    "\n",
    "    def get_embedding_model_dimension(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the embedding model dimension.\n",
    "\n",
    "        :return: Embedding model dimension.\n",
    "        :raises Exception: If model details are not present.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            embedding = self.__vector_store.get(\"embedding\", None)\n",
    "            if embedding:\n",
    "                dimension = embedding.get(\"dimension\", None)\n",
    "                if dimension:\n",
    "                    return dimension\n",
    "        raise Exception(\"Model details Not Present\")\n",
    "\n",
    "    def get_vector_index_schema(self) -> dict:\n",
    "        \"\"\"\n",
    "        Get the vector index schema.\n",
    "\n",
    "        :return: Vector index schema.\n",
    "        :raises Exception: If index schema is not present.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            index = self.__vector_store.get(\"index\", None)\n",
    "            if index:\n",
    "                schema = index.get(\"schema\", None)\n",
    "                if schema:\n",
    "                    return schema\n",
    "        raise Exception(\"Index Schema Not Present\")\n",
    "\n",
    "    def get_vector_index_primary_key(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the vector index primary key.\n",
    "\n",
    "        :return: Vector index primary key.\n",
    "        :raises Exception: If primary key information is not present.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            index = self.__vector_store.get(\"index\", None)\n",
    "            if index:\n",
    "                primary_key = index.get(\"primary_key\", None)\n",
    "                if primary_key:\n",
    "                    return primary_key\n",
    "        raise Exception(\"Index Primary key information Not Present\")\n",
    "\n",
    "    def get_vector_index_vector_column(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the vector index embedding vector column.\n",
    "\n",
    "        :return: Embedding vector column name.\n",
    "        :raises Exception: If embedding vector column information is not present.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            index = self.__vector_store.get(\"index\", None)\n",
    "            if index:\n",
    "                embedding_vector_column = index.get(\"embedding_vector_column\", None)\n",
    "                if embedding_vector_column:\n",
    "                    return embedding_vector_column\n",
    "        raise Exception(\"Index Embedding vector column information not Present.\")\n",
    "\n",
    "    def get_vector_endpoint(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the vector endpoint name.\n",
    "\n",
    "        :return: Vector endpoint name.\n",
    "        :raises Exception: If endpoint name details are not present.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            endpoint_name = self.__vector_store.get(\"endpoint_name\", None)\n",
    "            if endpoint_name:\n",
    "                return endpoint_name\n",
    "        raise Exception(\"Endpoint_name details Not Present\")\n",
    "\n",
    "    def get_vector_index(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the vector index name.\n",
    "\n",
    "        :return: Vector index name.\n",
    "        :raises Exception: If vector index name information is missing.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            index = self.__vector_store.get(\"index\", None)\n",
    "            if index:\n",
    "                index_name = index.get(\"name\", None)\n",
    "                if index_name:\n",
    "                    return index_name\n",
    "        raise Exception(\"Vector Index Name information missing in the config not Present\")\n",
    "\n",
    "    def get_generator_endpoint(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the generator endpoint name.\n",
    "\n",
    "        :return: Generator endpoint name.\n",
    "        :raises Exception: If LLM endpoint is not present.\n",
    "        \"\"\"\n",
    "        if self.__generator:\n",
    "            endpoint_name = self.__generator.get(\"openai_endpoint\")\n",
    "            if endpoint_name:\n",
    "                return endpoint_name\n",
    "        raise Exception(\"LLM endpoint not present\")\n",
    "\n",
    "    def get_vision_endpoint(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the vision endpoint name.\n",
    "\n",
    "        :return: Vision endpoint name.\n",
    "        :raises Exception: If vision endpoint is not present.\n",
    "        \"\"\"\n",
    "        if self.__vision:\n",
    "            endpoint_name = self.__vision.get(\"openai_endpoint\")\n",
    "            if endpoint_name:\n",
    "                return endpoint_name\n",
    "        raise Exception(\"Vision endpoint not present\")\n",
    "\n",
    "    def get_generator_model(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the generator model name.\n",
    "\n",
    "        :return: Generator model name.\n",
    "        :raises Exception: If LLM model is not present.\n",
    "        \"\"\"\n",
    "        if self.__generator:\n",
    "            openai_chat_model = self.__generator.get(\"openai_chat_model\")\n",
    "            if openai_chat_model:\n",
    "                return openai_chat_model\n",
    "        raise Exception(\"LLM Model not present\")\n",
    "\n",
    "    def get_vector_query_type(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the vector query type.\n",
    "\n",
    "        :return: Vector query type.\n",
    "        :raises Exception: If query type is not present.\n",
    "        \"\"\"\n",
    "        if self.__vector_store:\n",
    "            query_type = self.__vector_store.get(\"query_type\")\n",
    "            if query_type:\n",
    "                return query_type\n",
    "        raise Exception(\"Query Type not present\")\n",
    "\n",
    "    def get_generator_prompt(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the generator prompt.\n",
    "\n",
    "        :return: Generator prompt.\n",
    "        :raises Exception: If generator prompt is not present.\n",
    "        \"\"\"\n",
    "        if self.__prompt:\n",
    "            generator_prompt = self.__prompt.get(\"generator_prompt\")\n",
    "            if generator_prompt:\n",
    "                return generator_prompt\n",
    "        raise Exception(\"Generator prompt not present\")\n",
    "\n",
    "    def get_symbol_identifier_prompt(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the symbol identifier prompt.\n",
    "\n",
    "        :return: Symbol identifier prompt.\n",
    "        :raises Exception: If symbol identifier prompt is not present.\n",
    "        \"\"\"\n",
    "        if self.__prompt:\n",
    "            symbol_identifier_prompt = self.__prompt.get(\"symbol_identifier_prompt\")\n",
    "            if symbol_identifier_prompt:\n",
    "                return symbol_identifier_prompt\n",
    "        raise Exception(\"Symbol Identifier prompt not present\")\n",
    "\n",
    "    def get_symbol_conversation_prompt(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the symbol conversation prompt.\n",
    "\n",
    "        :return: Symbol conversation prompt.\n",
    "        :raises Exception: If symbol conversation prompt is not present.\n",
    "        \"\"\"\n",
    "        if self.__prompt:\n",
    "            symbol_conversation_prompt = self.__prompt.get(\"symbol_conversation_prompt\")\n",
    "            if symbol_conversation_prompt:\n",
    "                return symbol_conversation_prompt\n",
    "        raise Exception(\"Symbol Conversation prompt not present\")\n",
    "\n",
    "    def get_multiturn_prompt(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the multi-turn prompt.\n",
    "\n",
    "        :return: Multi-turn prompt.\n",
    "        :raises Exception: If multi-turn prompt is not present.\n",
    "        \"\"\"\n",
    "        if self.__prompt:\n",
    "            multiturn_prompt = self.__prompt.get(\"multiturn_prompt\")\n",
    "            if multiturn_prompt:\n",
    "                return multiturn_prompt\n",
    "        raise Exception(\"Multi-turn prompt not present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cb03c5a-a1d9-4b4b-8161-30e705ec9143",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    \"\"\"\n",
    "    A class to generate embeddings from a model deployed on Azure Databricks.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    deploy_client : mlflow.deployments.DeployClient\n",
    "        The deployment client for interacting with the model.\n",
    "    endpoint : str\n",
    "        The endpoint URL of the deployed model.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    __init__(endpoint: str):\n",
    "        Initializes the EmbeddingGenerator with the given endpoint.\n",
    "    generate_embeddings(text: str) -> List[float]:\n",
    "        Generates embeddings for the given text.\n",
    "    \"\"\"\n",
    "    def __init__(self, endpoint: str):\n",
    "        \"\"\"\n",
    "        Initialize the EmbeddingGenerator with the given endpoint.\n",
    "\n",
    "        :param endpoint: The endpoint URL of the deployed model.\n",
    "        \"\"\"\n",
    "        self.deploy_client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "        self.endpoint = endpoint\n",
    "\n",
    "    def generate_embeddings(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Generate embeddings for the given text.\n",
    "\n",
    "        :param text: The input text to generate embeddings for.\n",
    "        :return: A list of floats representing the embeddings.\n",
    "        :raises Exception: If there is an error generating embeddings.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.deploy_client.predict(endpoint=self.endpoint, inputs={\"input\": text})\n",
    "            embeddings = response.data[0][\"embedding\"]\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error generating embeddings: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearchManager:\n",
    "    \"\"\"\n",
    "    A class to manage vector search operations.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    __config : Config\n",
    "        The configuration object.\n",
    "    client : VectorSearchClient\n",
    "        The client for interacting with the vector search service.\n",
    "    index_name : str\n",
    "        The name of the vector index.\n",
    "    endpoint_name : str\n",
    "        The endpoint name of the vector search service.\n",
    "    embedding_dimension : int\n",
    "        The dimension of the embedding vectors.\n",
    "    primary_key : str\n",
    "        The primary key for the vector index.\n",
    "    embedding_vector_column : str\n",
    "        The column name for the embedding vectors.\n",
    "    index : Optional[dict]\n",
    "        The vector index object.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    __init__(config: Config):\n",
    "        Initializes the VectorSearchManager with the given configuration.\n",
    "    index_exists() -> bool:\n",
    "        Checks if the index exists.\n",
    "    get_index() -> Optional[dict]:\n",
    "        Gets the vector index object.\n",
    "    create_index():\n",
    "        Creates the vector database index.\n",
    "    add_documents(documents: List[dict]) -> bool:\n",
    "        Adds the documents to the vector database.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"\n",
    "        Initialize the VectorSearchManager with the given configuration.\n",
    "\n",
    "        :param config: The configuration object.\n",
    "        \"\"\"\n",
    "        self.__config = config\n",
    "        self.client = VectorSearchClient(disable_notice=True)\n",
    "        self.index_name = self.__config.get_vector_index()\n",
    "        self.endpoint_name = self.__config.get_vector_endpoint()\n",
    "        self.embedding_dimension = self.__config.get_embedding_model_dimension()\n",
    "        self.primary_key = self.__config.get_vector_index_primary_key()\n",
    "        self.embedding_vector_column = self.__config.get_vector_index_vector_column()\n",
    "        self.index = None\n",
    "        if not self.index_exists():\n",
    "            self.create_index()\n",
    "        else:\n",
    "            self.index = self.client.get_index(\n",
    "                index_name=self.index_name,\n",
    "                endpoint_name=self.endpoint_name\n",
    "            )\n",
    "\n",
    "    def index_exists(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the index exists.\n",
    "\n",
    "        :return: True if the index exists, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            existing_index = self.client.list_indexes(self.endpoint_name)\n",
    "            return self.index_name in [index[\"name\"] for index in existing_index[\"vector_indexes\"]]\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def get_index(self):\n",
    "        \"\"\"\n",
    "        Get the vector index object.\n",
    "\n",
    "        :return: The vector index object.\n",
    "        \"\"\"\n",
    "        return self.index\n",
    "\n",
    "    def create_index(self):\n",
    "        \"\"\"\n",
    "        Creates the vector database index.\n",
    "\n",
    "        :raises Exception: If there is an error creating the index.\n",
    "        \"\"\"\n",
    "        schema = self.__config.get_vector_index_schema()\n",
    "        filter_columns = []  # Define filter_columns if needed\n",
    "        for col in filter_columns:\n",
    "            schema[col] = \"string\"\n",
    "        if self.index_exists():\n",
    "            print(f\"Index {self.index_name} already exists\")\n",
    "            return schema\n",
    "        try:\n",
    "            self.index = self.client.create_direct_access_index(\n",
    "                endpoint_name=self.endpoint_name,\n",
    "                primary_key=self.primary_key,\n",
    "                index_name=self.index_name,\n",
    "                embedding_dimension=self.embedding_dimension,\n",
    "                embedding_vector_column=self.embedding_vector_column,\n",
    "                schema=schema\n",
    "            )\n",
    "            print(f\"Created index {self.index_name}\")\n",
    "        except Exception as e:\n",
    "            if \"Vector index\" in str(e) and \"is not ready\" in str(e):\n",
    "                print(f\"Index {self.index_name} is not ready. Retrying...\")\n",
    "                time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "                self.create_index()\n",
    "            else:\n",
    "                raise Exception(f\"Error creating index {self.index_name}: {str(e)}\")\n",
    "\n",
    "    def add_documents(self, documents: List[dict]) -> bool:\n",
    "        \"\"\"\n",
    "        Adds the documents to the vector database.\n",
    "\n",
    "        :param documents: List of documents to be added.\n",
    "        :return: True if documents are added successfully, False otherwise.\n",
    "        :raises Exception: If there is an error adding documents.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            index = self.client.get_index(self.endpoint_name, self.index_name)\n",
    "            upload_doc = index.upsert(documents)\n",
    "            if upload_doc[\"status\"] == \"SUCCESS\":\n",
    "                print(f\"{len(documents)} documents added to index {self.index_name}\")\n",
    "                return True\n",
    "            else:\n",
    "                raise Exception(f\"Error adding documents to index {self.index_name}: {str(upload_doc)}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error adding documents to index {self.index_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b03342c-4a37-470a-93fa-cd9301d517eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ImageExtract:\n",
    "  \"\"\"\n",
    "  A class to extract images from a PDF file, save them to a specified directory, and return metadata about the images.\n",
    "\n",
    "  Attributes:\n",
    "  ----------\n",
    "  file_path : str\n",
    "      The path to the PDF file from which images will be extracted.\n",
    "  image_path_prefix : str\n",
    "      A prefix for naming the extracted image files based on the PDF file name.\n",
    "\n",
    "  Methods:\n",
    "  -------\n",
    "  _sanitize_filename(filename: str) -> str:\n",
    "      Sanitizes a filename to be OS-compatible and safe for saving.\n",
    "  _convert_url_to_filename(image_url) -> str:\n",
    "      Converts a URL to a sanitized filename.\n",
    "  get_image_path(image_url, dir_destination_file) -> str:\n",
    "      Constructs the full path for saving an image.\n",
    "  save_image(url: str, image_base64: str, dir_destination_file: str) -> str:\n",
    "      Saves a base64-encoded image to the specified directory.\n",
    "  load_file() -> List[Document]:\n",
    "      Extracts images from the PDF, saves them, and returns metadata about the images.\n",
    "  \"\"\"\n",
    "  def __init__(self, file_path: str):\n",
    "    self.file_path = file_path\n",
    "    self.image_path_prefix =  os.path.basename(file_path).replace(\".\",\"-\").lower()\n",
    "    \n",
    "  def _sanitize_filename(self, filename: str) -> str:\n",
    "        os_name = platform.system()\n",
    "        filename = urllib.parse.unquote(filename)\n",
    "        if os_name != \"Windows\":\n",
    "            filename = unicodedata.normalize('NFKC', filename)\n",
    "        else:\n",
    "            # This is mainly for window machines used by developers\n",
    "            filename = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore').decode('ascii')\n",
    "        filename = re.sub(r'[^\\w\\s.-]', '', filename.lower())\n",
    "        return filename \n",
    "\n",
    "  def _convert_url_to_filename(self, image_url) -> str:\n",
    "        image_url = image_url.replace(\"#unknown-\", \"/\")\n",
    "        path = urllib.parse.urlparse(image_url).path\n",
    "        filename = os.path.basename(path)\n",
    "        sanitized_filename = self._sanitize_filename(filename)\n",
    "        return sanitized_filename \n",
    "\n",
    "  def get_image_path(self, image_url, dir_destination_file) -> str:\n",
    "          image_name = self._convert_url_to_filename(image_url)\n",
    "\n",
    "          image_file_path = os.path.join(\n",
    "              dir_destination_file, \"image\", f\"{image_name}\")\n",
    "          \n",
    "          return image_file_path    \n",
    "\n",
    "  def save_image(self, url: str, image_base64: str, dir_destination_file: str) -> str:\n",
    "        image_dir = os.path.join(dir_destination_file, \"image\")\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        image_path = self.get_image_path(url, dir_destination_file)\n",
    "        image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "        with open(image_path, 'wb') as file:\n",
    "            file.write(image_bytes)\n",
    "    \n",
    "        return image_path    \n",
    "      \n",
    "  def load_file(self):\n",
    "        doc = fitz.open(self.file_path)\n",
    "        dir_destination_file = os.path.dirname(\n",
    "            self.file_path).replace(\"pending\", \"images\")\n",
    "        image_collection = {}\n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc.load_page(page_num)\n",
    "            images = page.get_images(full=True)\n",
    "            for img_index, img_info in enumerate(images):\n",
    "                img_index += 1\n",
    "                xref = img_info[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                if base_image:\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    image = Image.open(BytesIO(image_bytes))\n",
    "                    if image.getbbox() and image.size[0] > 100 and image.size[1] > 100:  # Check if the image is not blank and larger than 50x50\n",
    "                        buffer = BytesIO(base_image[\"image\"]).getvalue()\n",
    "                        encoded_image = base64.b64encode(buffer).decode()\n",
    "                        image_file_path = os.path.join(\n",
    "                            dir_destination_file, \"image\", f\"{os.path.basename(self.file_path).lower()}_image_page{page_num + 1}_img_nmbr{img_index}.{base_image['ext']}\")\n",
    "                        image_collection[image_file_path] = encoded_image\n",
    "                        self.save_image(image_file_path, encoded_image, dir_destination_file=dir_destination_file)\n",
    "        return [Document(\n",
    "                    page_content=\"\",\n",
    "                    metadata={\n",
    "                        \"source\": self.file_path,\n",
    "                        \"image_collection\": image_collection\n",
    "                    })]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0fcb88e-8a8b-44c6-8822-d79b3c9d1e21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TableExtract:\n",
    "  \"\"\"\n",
    "  A class to extract tables from a PDF file and return them as a list of Document objects.\n",
    "\n",
    "  Attributes:\n",
    "  ----------\n",
    "  file_path : str\n",
    "      The path to the PDF file from which tables will be extracted.\n",
    "\n",
    "  Methods:\n",
    "  -------\n",
    "  load_file() -> List[Document]:\n",
    "      Extracts tables from the PDF, converts them to CSV format, and returns them as a list of Document objects with metadata.\n",
    "  \"\"\"\n",
    "  def __init__(self, file_path: str):\n",
    "    self.file_path = file_path\n",
    "\n",
    "  def load_file(self) -> List[Document]:\n",
    "          doc = fitz.open(self.file_path)\n",
    "          current_page_num = None  # For testing\n",
    "          df_final = {}\n",
    "          df_list = []\n",
    "          for page_num in range(doc.page_count):\n",
    "              page = doc[page_num]\n",
    "              tables = page.find_tables(\n",
    "                  horizontal_strategy=\"text\", vertical_strategy=\"text\")\n",
    "              page_tables_data = []\n",
    "              metadata = {\n",
    "                  \"source\": self.file_path,\n",
    "                  \"file_path\": self.file_path,\n",
    "                  \"total_pages\": len(doc),\n",
    "              }\n",
    "              for table_num, table in enumerate(tables):\n",
    "                  original_result = table.extract()\n",
    "                  df = pd.DataFrame(table.extract())\n",
    "                  df_csv = df.to_csv(sep='|', index=False, header=False)\n",
    "                  page_tables_data.append(df_csv)\n",
    "              df_final[f\"Page_{page_num + 1}\"] = page_tables_data\n",
    "              df_list.append(Document(page_content=str(\n",
    "                  page_tables_data), metadata=metadata))\n",
    "          return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b50aeeb-ec1c-4be0-a625-c8a36e1c9c3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class AzureGpt4VService:\n",
    "    \"\"\"\n",
    "    A service class to interact with Azure's GPT-4V model for generating image descriptions.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    __llm_endpoint : str\n",
    "        The endpoint URL for the GPT-4V model.\n",
    "    __llm_api_key : str\n",
    "        The API key for authenticating requests to the GPT-4V model.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    get_image_format(base64_source: str) -> str:\n",
    "        Determines the format of a base64-encoded image.\n",
    "    image_description(images: list, prompt: str, detail_mode: str, image_urls: list = None, deployment_name: Optional[str] = None, llm_endpoint: Optional[str] = None, llm_apAzureGpt4VServicei_version: Optional[str] = None) -> list:\n",
    "        Generates descriptions for a list of images using the GPT-4V model.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm_endpoint: Optional[str] = None,llm_api_key: Optional[str] = None): \n",
    "        self.__llm_endpoint = llm_endpoint\n",
    "        self.__llm_api_key = \"#####\"\n",
    "\n",
    "    def get_image_format(self, base64_source: str):\n",
    "        image_stream = BytesIO(base64.b64decode(base64_source))\n",
    "        image = Image.open(image_stream)\n",
    "        image_format = image.format\n",
    "        return image_format\n",
    "\n",
    "    def image_description(\n",
    "        self,\n",
    "        images: list,\n",
    "        prompt: str,\n",
    "        detail_mode: str,\n",
    "        image_urls: list = None,\n",
    "        deployment_name: Optional[str] = None,\n",
    "        llm_endpoint: Optional[str] = None,\n",
    "        llm_api_version: Optional[str] = None\n",
    "    ):\n",
    "        self.__init__(llm_endpoint, llm_api_version)\n",
    "        messages = []\n",
    "        messages.append({\"role\": \"system\", \"content\": prompt})\n",
    "        documents = []\n",
    "        content = []\n",
    "        for i, image in enumerate(image_urls):\n",
    "            format = self.get_image_format(image).lower()\n",
    "            if image:\n",
    "                content.append({\"type\": \"text\", \"text\": f\"!()[{image_urls[i][0]}]\"})\n",
    "            content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/{format};base64,{image}\", \"detail\": detail_mode}})\n",
    "            messages.append({\"role\": \"user\", \"content\": content})\n",
    "            payload = json.dumps({\"messages\": messages, \"enhancements\": {\"ocr\": {\"enabled\": False}, \"grounding\": {\"enabled\": True}}, \"temperature\": 0.1, \"max_tokens\": 1000})\n",
    "            headers = {\n",
    "                'api-key': self.__llm_api_key,\n",
    "                'Content-Type': 'application/json'\n",
    "            }\n",
    "            response = requests.request(\"POST\", llm_endpoint, headers=headers, data=payload)\n",
    "            response = json.loads(response.text)\n",
    "            if response[\"choices\"][0][\"message\"][\"role\"] == \"assistant\":\n",
    "                documents.append(Document(page_content=response['choices'][0]['message']['content'], metadata={\"source\": images[0]}))\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434f830c-e205-47fc-99c4-6f0857c821dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deploy_client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "class Upload:\n",
    "  \"\"\"\n",
    "  A class to handle the uploading of documents to a vector database.\n",
    "\n",
    "  Attributes:\n",
    "  ----------\n",
    "  file_path : List[str]\n",
    "      List of file paths to be processed.\n",
    "  file_name : str\n",
    "      Name of the file to be processed.\n",
    "  config_path : str\n",
    "      Path to the configuration file.\n",
    "  vector_search_manager : VectorSearchManager\n",
    "      Instance of the VectorSearchManager to manage vector search operations.\n",
    "\n",
    "  Methods:\n",
    "  -------\n",
    "  document_exists(file_path: str) -> bool:\n",
    "      Checks if a document already exists in the vector database.\n",
    "  process_documents() -> list:\n",
    "      Processes and uploads documents to the vector database.\n",
    "  \"\"\"\n",
    "  def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        file_name: str,\n",
    "        config_path: str,\n",
    "        filter_param: dict = {}                                                                                                \n",
    "    ):\n",
    "    self.__config = Config(config_path)\n",
    "    self.__file_path = file_path\n",
    "    self.__file_name = file_name   \n",
    "    self.__embedding_generator = EmbeddingGenerator(endpoint=self.__config.get_embedding_model()) #Instance of the EmbeddingGenerator to generate embeddings for documents.    \n",
    "    \n",
    "    self.vector_search_manager = VectorSearchManager(self.__config)\n",
    "    self.filter_param = filter_param\n",
    "\n",
    "  def document_exists(self) -> bool:\n",
    "    try:\n",
    "        if not self.vector_search_manager.index_exists():\n",
    "            return False\n",
    "        else:\n",
    "            query_text=\"*\"            \n",
    "            query_vector = self.__embedding_generator.generate_embeddings(query_text)\n",
    "            index = self.vector_search_manager.get_index()\n",
    "            res = index.similarity_search(query_vector=query_vector,columns=[\"page_content\",\"content_vector\"],filters={\"source\": self.__file_path})\n",
    "            result = res.get(\"result\")\n",
    "            return True if result and result.get(\"data_array\") else False\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Exception: {str(e)}\")\n",
    "\n",
    "  def process_documents(self):\n",
    "            \"\"\"\n",
    "            Uploads the documents to the vector database.\n",
    "            \"\"\"\n",
    "            image_descriptions = []\n",
    "            file_result = {\"file_name\":self.__file_name}\n",
    "            if self.document_exists():\n",
    "                file_result[\"status\"] = \"skipped\"\n",
    "                file_result[\"error\"] = \"Document already present\"\n",
    "                return file_result\n",
    "            _, file_extension = os.path.splitext(self.__file_name)\n",
    "            file_extension = file_extension[1:]\n",
    "            loader_config =  self.__config.get_loader_for_extension(file_extension)\n",
    "        # try:\n",
    "            if loader_config:\n",
    "                loader = globals()[loader_config.loader_class](file_path=self.__file_path,**loader_config.loader_kwargs)\n",
    "                documents = loader.load_and_split()\n",
    "                splitter = globals()[loader_config.splitter_class](**loader_config.splitter_kwargs)\n",
    "                documents = splitter.split_documents(documents)\n",
    "                if file_extension == \"pdf\":\n",
    "                    #### Image description from PDF\n",
    "                    try:\n",
    "                        image_extract = ImageExtract(self.__file_path)\n",
    "                        pdf_images = image_extract.load_file()\n",
    "                        image_collection = pdf_images[0].metadata[\"image_collection\"]\n",
    "                        img_urls = list(image_collection.keys())\n",
    "                        img_encodings = list(image_collection.values())\n",
    "                        for img_url, img_encoding in zip(img_urls, img_encodings):\n",
    "                            gptv4_service = AzureGpt4VService()\n",
    "                            image_descriptions = gptv4_service.image_description(\n",
    "                                images=[img_url],\n",
    "                                prompt=\"What is this image about?\",\n",
    "                                detail_mode=\"auto\",\n",
    "                                image_urls=[img_encoding],\n",
    "                                llm_endpoint=self.__config.get_vision_endpoint()                    \n",
    "                            )\n",
    "                            documents.extend(image_descriptions)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error extracting image descriptions from PDF: {e}\")                       \n",
    "                    ### Table Extraction from PDF\n",
    "                    try:\n",
    "                        table_extraction = TableExtract(self.__file_path)\n",
    "                        tables = table_extraction.load_file()\n",
    "                        documents.extend(tables)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error extracting tables from PDF: {e}\")\n",
    "\n",
    "                ## Data to store in vectorDB database\n",
    "                processed_documents = []\n",
    "                for page_num, doc in enumerate(documents, 1):                   \n",
    "                    embeddings = self.__embedding_generator.generate_embeddings(doc.page_content)\n",
    "                    if not doc.metadata:\n",
    "                        doc.metadata[\"page_number\"] = str(page_num)\n",
    "                        doc.metadata[\"source\"] = str(self.__file_path)                    \n",
    "                    for col in self.filter_param:\n",
    "                        doc.metadata[col] = doc.metadata.get(col, self.filter_param.get(col, \"\"))\n",
    "                    processed_documents.append({\"id\": f'{uuid.uuid4()}', \"page_content\": doc.page_content, \"source\": str(self.__file_path), \"metadata\": json.dumps(doc.metadata), \"content_vector\": embeddings, **{col: doc.metadata[col] for col in self.filter_param}})\n",
    "                print(f\"Uploading {len(processed_documents)} documents to vector database\")\n",
    "                self.vector_search_manager.add_documents(processed_documents)\n",
    "                file_result[\"status\"] = \"success\"\n",
    "                file_result[\"documents\"] = processed_documents            \n",
    "            else:\n",
    "                file_result[\"status\"] = \"failure\"\n",
    "                file_result[\"error\"] = f\"Unsupported file format:{self.__file_name}\"\n",
    "        # except Exception as e:\n",
    "        #     file_result[\"status\"] = \"failure\"\n",
    "        #     file_result[\"error\"] = str(e)\n",
    "            return file_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a620fc76-678d-46dc-bc54-9f2628cf42db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "config_path = \"/config/wallstreet_config.json\"\n",
    "org_folder_path = '' # Folder Path\n",
    "\n",
    "total_files = 0\n",
    "success_files = 0\n",
    "failure_files = 0\n",
    "skipped_files = 0\n",
    "process_start_time = dt.now()    \n",
    "for files in os.listdir(org_folder_path):\n",
    "    start_time = dt.now()\n",
    "    file_path = os.path.join(org_folder_path, files)\n",
    "    total_files += 1\n",
    "    print(f\"Processing {files}\")\n",
    "    upload_list = Upload(file_path=file_path, file_name=files, config_path=config_path, filter_param={})\n",
    "    result = upload_list.process_documents()\n",
    "    if result[\"status\"] == \"success\":\n",
    "        success_files += 1\n",
    "        print(f\"Success: {files}\")\n",
    "    elif result[\"status\"] == \"skipped\":\n",
    "        skipped_files += 1\n",
    "        print(f\"Skipped: {files}\")\n",
    "    else:\n",
    "        failure_files += 1\n",
    "        print(result[\"error\"])\n",
    "end_time = dt.now()\n",
    "total_time =  (end_time - start_time).total_seconds()\n",
    "print(f\"COMPANY Time Taken {total_time} seconds\")\n",
    "print(f\"Total files: {total_files}, Success files: {success_files}, Skipped files: {skipped_files}, Failure files: {failure_files}\")\n",
    "total_time = (dt.now() - process_start_time).total_seconds()\n",
    "print(f\"TOTAL PROCESSING TIME: {total_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Document_Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
